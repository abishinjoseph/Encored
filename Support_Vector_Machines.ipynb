{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrJ3NEV8WJn+ZUNW9CZr2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abishinjoseph/Encored/blob/main/Support_Vector_Machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kAmNjSkkZCF",
        "outputId": "717268d1-bd23-44d0-e5aa-ecc5df173027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ID Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  Worst Radius  Worst Texture  Worst Perimeter  Worst Area  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   Worst Smoothness  Worst Compactness  Worst Concavity  Worst Concave Points  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   Worst Symmetry  Worst Fractal Dimension  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "Accuracy: 0.956140350877193\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.95      0.99      0.97        71\n",
            "           M       0.97      0.91      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Breast Cancer Wisconsin dataset from the file path\n",
        "file_path = \"wdbc.data\"\n",
        "\n",
        "# Define column names based on dataset description\n",
        "column_names = ['ID', 'Diagnosis', 'Mean Radius', 'Mean Texture', 'Mean Perimeter', 'Mean Area', 'Mean Smoothness',\n",
        "                'Mean Compactness', 'Mean Concavity', 'Mean Concave Points', 'Mean Symmetry', 'Mean Fractal Dimension',\n",
        "                'SE Radius', 'SE Texture', 'SE Perimeter', 'SE Area', 'SE Smoothness', 'SE Compactness', 'SE Concavity',\n",
        "                'SE Concave Points', 'SE Symmetry', 'SE Fractal Dimension', 'Worst Radius', 'Worst Texture', 'Worst Perimeter',\n",
        "                'Worst Area', 'Worst Smoothness', 'Worst Compactness', 'Worst Concavity', 'Worst Concave Points',\n",
        "                'Worst Symmetry', 'Worst Fractal Dimension']\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(file_path, header=None, names=column_names)\n",
        "\n",
        "# Print the first few rows of the dataset to verify the loading\n",
        "print(data.head())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(['ID', 'Diagnosis'], axis=1)  # Features\n",
        "y = data['Diagnosis']  # Target variable\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Support Vector Classifier (SVC)\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    }
  ]
}